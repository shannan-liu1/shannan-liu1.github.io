---
layout: post
title:  "Tutorial: Image Classification & Transfer Learning Tutorial"
categories: blog assignment
permalink: posts/HW-3
author: Shannan Liu
---

# Image Classifcation Tutorial

## Introduction
In this blog post, we're going to explore image classification with convolutional neural networks. More specifically, we're going to build successively complex models to perform image classification so that we can explore tools such as data augmentation, image preprocessing, and transfer learning.

## 1. Load Packages and Obtain Data

First, let's obtain the relevant imports and data

```python
import os
import tensorflow as tf
from tensorflow.keras import utils, layers, models

import numpy as np

import matplotlib as mpl
import matplotlib.pyplot as plt
```

Get sample dataset from Tensorflow team. The data is split into a training, validation, and testing set.

```python
# location of data
_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'

# download the data and extract it
path_to_zip = utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)

# construct paths
PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')

train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'validation')

# parameters for datasets
BATCH_SIZE = 32
IMG_SIZE = (160, 160)

# construct train and validation datasets
train_dataset = utils.image_dataset_from_directory(train_dir,
                                                   shuffle=True,
                                                   batch_size=BATCH_SIZE,
                                                   image_size=IMG_SIZE)

validation_dataset = utils.image_dataset_from_directory(validation_dir,
                                                        shuffle=True,
                                                        batch_size=BATCH_SIZE,
                                                        image_size=IMG_SIZE)

# construct the test dataset by taking every 5th observation out of the validation dataset
val_batches = tf.data.experimental.cardinality(validation_dataset)
test_dataset = validation_dataset.take(val_batches // 5)
validation_dataset = validation_dataset.skip(val_batches // 5)
```

### Working with Datasets
Before we begin modelling, we should gain some familiarity with using Tensorflow Datasets.

Here, we'll demonstrate a two row visualisation of cats & dogs with the training dataset. The first row will be composed of random cat pictures, and the second row will be composed of random dog pictures.

```python
# first, we'll extract class names from dataset
class_names = train_dataset.class_names
class_names

# now let's create our visualisation function
def plot_animals():
  """
  create a two-row visusalisation of cats & dogs in the training dataset
  """
  plt.figure(figsize=(10, 10)) # set plot figsize

  # get images and labels from training set
  for images, labels in train_dataset.take(1):
    # get list of cat images
    cat_images = images[np.array(np.array(labels) == 0)]

    # get list of dog images
    dog_images = images[np.array(np.array(labels) == 1)]

    # plot 2 rows of 3 images of cats and dogs - total 6 images
    for i in range(6):

      # set up subplots
      ax = plt.subplot(2, 3, i + 1)
      if i < 3: # plot cats in 1st row
        plt.imshow(cat_images[i].numpy().astype("uint8"))
        plt.title('cats')
        plt.axis("off")
      else: # plot dogs in 2nd row
        plt.imshow(dog_images[i].numpy().astype("uint8"))
        plt.title('dogs')
        plt.axis("off")
```

Using the function
```python
plot_animals() # run function
```
![_config.yml]({{ site.baseurl }}/images/img-class-1-hw3.png)


### Check Label Frequencies
Next, we should check our label frequencies. This is important because a baseline model will always guess the label with the highest frequency. Thus, if the number of cat and dog labels in our dataset are not balanced, then our model's baseline performance will not be 50%, meaning we have to judge our model by another benchmark (i.e. being better than 60% is considered a good model if our model has 60% cat images and 40% dog images for instance).

However, before we do that, let's add some code that will enable us to read our data more efficiently.

```python
# related to reading data more rapidly
AUTOTUNE = tf.data.AUTOTUNE

train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)
validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)
test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)
```

Now we check the frequency of our data's labels. Below, I show two methods for doing so. The first method uses an iterator, and the second method uses a for loop.

```python
# using iterator to compute number of labels corresponding to cat (0) and dog (1)
labels_iterator = train_dataset.unbatch().map(lambda image, label: label).as_numpy_iterator()
print(f"Number of cats = {np.sum(np.array(list(labels_iterator))==0)}")
labels_iterator = train_dataset.unbatch().map(lambda image, label: label).as_numpy_iterator()
print(f"Number of dogs = {np.sum(np.array(list(labels_iterator))==1)}")

Number of cats = 1000
Number of dogs = 1000
```
```python
# alternative method
# using for loop to compute number of labels corresponding to cat (0) and dog (1)
dog_count = 0
cat_count = 0
for images, labels in train_dataset.take(len(train_dataset)):
  dog_count += sum(np.array(labels))
  cat_count += sum(np.array(labels) == 0)

print(f"Number of cats = {cat_count}")
print(f"Number of dogs = {dog_count}")

Number of cats = 1000
Number of dogs = 1000
```
In this case, our baseline model would have an accuracy of 50% because there is an even split in the number of dogs and cats in our dataset. This is perfect, and weâ€™ll treat this as the benchmark for improvement. Our models should do much better than baseline to be considered good data science achievements.


## 2. First Model
Now we'll move onto builing our first model, which will be comprised of (1) convolutional layers that help us extract features from our images and (2) dense layers that will perform the classification task for us. Our output comprises of 2 neurons because we want to make predictions on 2 classes.

```python
model1 = tf.keras.Sequential([
  # feature extraction
  layers.Conv2D(64,(3,3),activation = 'relu', input_shape = (160,160,3)),
  layers.BatchNormalization(),
  layers.MaxPooling2D((2,2)),
  layers.Conv2D(32,(3,3),activation = 'relu'),
  layers.BatchNormalization(),
  layers.MaxPooling2D((2,2)),
  layers.Conv2D(32,(3,3,),activation = 'relu'),
  layers.BatchNormalization(),
  layers.MaxPooling2D((2,2)),
  layers.Conv2D(32,(3,3,),activation = 'relu'),
  layers.BatchNormalization(),
  layers.MaxPooling2D((2,2)),
  layers.Flatten(),

  # classification
  layers.Dense(128,activation = 'relu'),
  layers.Dropout(0.2),
  layers.Dense(256,activation = 'relu'),
  layers.Dropout(0.2),
  layers.Dense(256,activation = 'relu'),
  layers.Dropout(0.2),
  layers.Dense(128,activation = 'relu'),
  layers.Dense(2) # output layer
])
```
The model summary below shows us the number of parameters in our model.
```python
model1.summary()
```
```
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 conv2d (Conv2D)             (None, 158, 158, 64)      1792

 batch_normalization (BatchN  (None, 158, 158, 64)     256
 ormalization)

 max_pooling2d (MaxPooling2D  (None, 79, 79, 64)       0
 )

 conv2d_1 (Conv2D)           (None, 77, 77, 32)        18464

 batch_normalization_1 (Batc  (None, 77, 77, 32)       128
 hNormalization)

 max_pooling2d_1 (MaxPooling  (None, 38, 38, 32)       0
 2D)

 conv2d_2 (Conv2D)           (None, 36, 36, 32)        9248

 batch_normalization_2 (Batc  (None, 36, 36, 32)       128
 hNormalization)

 max_pooling2d_2 (MaxPooling  (None, 18, 18, 32)       0
 2D)

 conv2d_3 (Conv2D)           (None, 16, 16, 32)        9248

 batch_normalization_3 (Batc  (None, 16, 16, 32)       128
 hNormalization)

 max_pooling2d_3 (MaxPooling  (None, 8, 8, 32)         0
 2D)

 flatten (Flatten)           (None, 2048)              0

 dense (Dense)               (None, 128)               262272

 dropout (Dropout)           (None, 128)               0

 dense_1 (Dense)             (None, 256)               33024

 dropout_1 (Dropout)         (None, 256)               0

 dense_2 (Dense)             (None, 256)               65792

 dropout_2 (Dropout)         (None, 256)               0

 dense_3 (Dense)             (None, 128)               32896

 dense_4 (Dense)             (None, 2)                 258

=================================================================
Total params: 433,634
Trainable params: 433,314
Non-trainable params: 320
_________________________________________________________________
```
